# ============================
# üì¶ IMPORTS - Gi·∫£i th√≠ch m·ª•c ƒë√≠ch t·ª´ng g√≥i
# ============================
from typing import List, Optional  # üëâ Ki·ªÉu d·ªØ li·ªáu cho type hinting (List, Optional)
from agno.tools import tool        # üëâ Decorator ƒë·ªÉ ƒëƒÉng k√Ω tool cho agno framework
import logging                     # üëâ Ghi log cho qu√° tr√¨nh x·ª≠ l√Ω, debug
import chromadb                    # üëâ Th∆∞ vi·ªán thao t√°c v·ªõi vector database Chroma
from chromadb.config import Settings  # üëâ C·∫•u h√¨nh cho ChromaDB (v√≠ d·ª•: ƒë∆∞·ªùng d·∫´n l∆∞u tr·ªØ)
import re                          # üëâ X·ª≠ l√Ω chu·ªói, t√°ch c√¢u, t√°ch object b·∫±ng regex
from sentence_transformers import SentenceTransformer  # üëâ Model embedding c√¢u (sentence-transformers)
import numpy as np                 # üëâ X·ª≠ l√Ω m·∫£ng s·ªë, chuy·ªÉn ƒë·ªïi embedding sang numpy array
import torch                     # üëâ S·ª≠ d·ª•ng PyTorch cho m√¥ h√¨nh Video-LLaVA
from PIL import Image # üëâ X·ª≠ l√Ω ·∫£nh (PIL Image) ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi m√¥ h√¨nh Video-LLaVA
from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration  # üëâ S·ª≠ d·ª•ng m√¥ h√¨nh Video-LLaVA (LlavaNext) t·ª´ transformers
from transformers import AutoTokenizer # üëâ Tokenizer cho m√¥ h√¨nh Video-LLaVA (LlavaNext)
import logging                   # üëâ Ghi log cho qu√° tr√¨nh x·ª≠ l√Ω, debug
import re                         # üëâ X·ª≠ l√Ω chu·ªói, t√°ch c√¢u, t√°ch object b·∫±ng regex
import numpy as np               # üëâ X·ª≠ l√Ω m·∫£ng s·ªë, chuy·ªÉn ƒë·ªïi embedding sang numpy array
from typing import List, Optional   # üëâ Ki·ªÉu d·ªØ li·ªáu cho type hinting (List, Optional)
from PIL import Image # üëâ X·ª≠ l√Ω ·∫£nh (PIL Image) ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi m√¥ h√¨nh Video-LLaVA
from sentence_transformers import SentenceTransformer # üëâ Model embedding c√¢u (sentence-transformers)
from chromadb.config import Settings # üëâ C·∫•u h√¨nh cho ChromaDB (v√≠ d·ª•: ƒë∆∞·ªùng d·∫´n l∆∞u tr·ªØ)
from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration # üëâ S·ª≠ d·ª•ng m√¥ h√¨nh Video-LLaVA (LlavaNext) t·ª´ transformers

"""
Pipeline for extracting, enriching, embedding, and storing statements from video frames using LLaVA-NeXT and sentence-transformers.
Code style: professional, concise, consistent, with clear comments and separation of imports and logic.
"""

# ============================
# üì¶ IMPORTS - All at top as per code standards
# ============================


class FrameInfo:
    """
    ÔøΩ ƒê·ªëi t∆∞·ª£ng ch·ª©a th√¥ng tin v·ªÅ m·ªôt frame h√¨nh ·∫£nh, bao g·ªìm ·∫£nh, id frame, id video, id scene.
    """
    def __init__(self, frame, frame_id: str, video_id: str, scene_id: Optional[str] = None):
        self.frame = frame  # ·∫¢nh (PIL.Image)
        self.frame_id = frame_id
        self.video_id = video_id
        self.scene_id = scene_id

class StatementItem:
    """
    üìù ƒê·ªëi t∆∞·ª£ng ch·ª©a m·ªôt statement (ph√°t bi·ªÉu) tr√≠ch xu·∫•t t·ª´ frame, k√®m metadata c∆° b·∫£n.
    """
    def __init__(self, text: str, frame_id: str, video_id: str, scene_id: Optional[str]):
        self.text = text
        self.frame_id = frame_id
        self.video_id = video_id
        self.scene_id = scene_id


class EmbeddedStatement:
    """
    üß© ƒê·ªëi t∆∞·ª£ng ch·ª©a statement ƒë√£ embedding (vector h√≥a), bao g·ªìm metadata v√† vector embedding.
    """
    def __init__(self, text: str, frame_id: str, video_id: str, scene_id: Optional[str], embedding: List[float]):
        self.text = text
        self.frame_id = frame_id
        self.video_id = video_id
        self.scene_id = scene_id
        self.embedding = embedding


class StatementIndexingTools:
    """
    üìù B·ªô c√¥ng c·ª• ti·ªÅn x·ª≠ l√Ω cho indexing statement (ph√°t bi·ªÉu, c√¢u, ƒëo·∫°n) theo ki·∫øn tr√∫c agno.
    D√πng ƒë·ªÉ tr√≠ch xu·∫•t, enrich, embedding v√† l∆∞u tr·ªØ c√°c statement t·ª´ frame h√¨nh ·∫£nh v√†o vector database.
    """
    def __init__(self, video_llava_model_id: str = "lmms-lab/LLaVA-Video-7B-Qwen2", embedding_model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """
        Kh·ªüi t·∫°o tool, logger, v√† embedding model. Kh√¥ng s·ª≠ d·ª•ng VideoLanguageProcessor, t·ª± implement pipeline Video-LLaVA.
        Args:
            video_llava_model_id: Model id cho Video-LLaVA (m·∫∑c ƒë·ªãnh: lmms-lab/LLaVA-Video-7B-Qwen2, model th·∫≠t tr√™n HuggingFace)
            embedding_model_name: T√™n model embedding cho sentence-transformers
        """
        self.logger = logging.getLogger(__name__)
        self.video_llava_model_id = video_llava_model_id  # L∆∞u model_id ƒë·ªÉ d√πng cho pipeline
        self.torch = torch
        self.device = "cuda" if torch.cuda.is_available() else "cpu"  # T·ª± ƒë·ªông ch·ªçn thi·∫øt b·ªã
        self.llava_processor = LlavaNextProcessor.from_pretrained(video_llava_model_id)
        self.llava_model = LlavaNextForConditionalGeneration.from_pretrained(video_llava_model_id)
        self.llava_model = self.llava_model.to(self.device)
        # LLaVA-NeXT: tokenizer ph·∫£i load ri√™ng

        self.llava_tokenizer = AutoTokenizer.from_pretrained(video_llava_model_id)
        # üß† Kh·ªüi t·∫°o sentence-transformers model m·ªôt l·∫ßn duy nh·∫•t
        self.embedding_model_name = embedding_model_name
        self.embedding_model = SentenceTransformer(embedding_model_name)
        
    def _run_llava_inference(self, frame, prompt, max_new_tokens=128):
        """
        üß† H√†m n·ªôi b·ªô ch·∫°y inference Video-LLaVA cho m·ªôt frame v√† prompt.
        Args:
            frame: ·∫¢nh ƒë·∫ßu v√†o (numpy array ho·∫∑c PIL Image)
            prompt: Prompt d·∫°ng text cho model
            max_new_tokens: S·ªë token sinh t·ªëi ƒëa
        Returns:
            response: Chu·ªói text tr·∫£ v·ªÅ t·ª´ model
        """

        # Chuy·ªÉn frame sang PIL Image n·∫øu c·∫ßn
        if not isinstance(frame, Image.Image):
            frame = Image.fromarray(frame)
        # Tokenize prompt
        input_ids = self.llava_tokenizer(prompt, return_tensors="pt").input_ids.to(self.device)
        # Process image (LlavaNextProcessor has .image_processor attribute)
        image_tensor = self.llava_processor.image_processor(frame, return_tensors="pt").pixel_values.to(self.device)
        inputs = {
            'input_ids': input_ids,
            'pixel_values': image_tensor
        }
        with self.torch.no_grad():
            generated_ids = self.llava_model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                do_sample=False
            )
            response = self.llava_tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
        return response
       
    @tool(
        name="embed_statements",
        description="Nh·∫≠n v√†o danh s√°ch statement (list[StatementItem]), tr·∫£ v·ªÅ list EmbeddedStatement v·ªõi embedding vector t∆∞∆°ng ·ª©ng.",
        cache_results=False
    )
    def embed_statements(self, items: List[StatementItem], model_name: Optional[str] = None) -> List[EmbeddedStatement]:
        """
        Nh√∫ng c√°c StatementItem th√†nh vector embedding b·∫±ng sentence-transformers, tr·∫£ v·ªÅ list EmbeddedStatement.
        Args:
            items: List[StatementItem] - Danh s√°ch statement c·∫ßn embedding
            model_name: T√™n model embedding (n·∫øu None s·∫Ω d√πng model ƒë√£ kh·ªüi t·∫°o trong __init__)
        Returns:
            List[EmbeddedStatement] - Danh s√°ch statement ƒë√£ embedding (bao g·ªìm metadata v√† vector)
        """
        model = self.embedding_model if model_name is None or model_name == self.embedding_model_name else SentenceTransformer(model_name)  # üß† D√πng model ƒë√£ kh·ªüi t·∫°o n·∫øu kh√¥ng truy·ªÅn model_name
        self.logger.info(f"Embedding {len(items)} statements b·∫±ng model: {model_name or self.embedding_model_name}")
        try:
            texts = [item.text for item in items]
            embeddings = model.encode(texts, show_progress_bar=False, convert_to_numpy=True)
            embedded_items = [
                EmbeddedStatement(
                    text=item.text,
                    frame_id=item.frame_id,
                    video_id=item.video_id,
                    scene_id=item.scene_id,
                    embedding=embeddings[i].tolist() if hasattr(embeddings[i], 'tolist') else list(embeddings[i])
                )
                for i, item in enumerate(items)
            ]
            return embedded_items
        except Exception as e:
            self.logger.error(f"L·ªói khi embedding statements: {e}")
            return []

    @tool(
        name="save_embeddings_to_vectordb",
        description="L∆∞u embedding vectors v√†o vector database Chroma. Nh·∫≠n v√†o list EmbeddedStatement (bao g·ªìm embedding, text, metadata).",
        cache_results=False
    )
    def save_embeddings_to_vectordb(self, embedded_items: List[EmbeddedStatement], collection_name: str = "statements") -> bool:
        """
        L∆∞u danh s√°ch EmbeddedStatement (bao g·ªìm embedding vector v√† metadata) v√†o vector database Chroma.
        Args:
            embedded_items: List[EmbeddedStatement] - Danh s√°ch statement ƒë√£ embedding
            collection_name: T√™n collection trong Chroma
        Returns:
            True n·∫øu l∆∞u th√†nh c√¥ng, False n·∫øu c√≥ l·ªói
        """
        self.logger.info(f"L∆∞u {len(embedded_items)} embedding v√†o Chroma collection: {collection_name}")
        try:
            client = chromadb.Client(Settings(persist_directory="./chroma_data"))
            # T·∫°o collection n·∫øu ch∆∞a c√≥
            if collection_name not in [c.name for c in client.list_collections()]:
                collection = client.create_collection(collection_name)
            else:
                collection = client.get_collection(collection_name)
            # Chu·∫©n b·ªã d·ªØ li·ªáu
            ids = [f"{item.video_id}_{item.frame_id}_{i}" for i, item in enumerate(embedded_items)]
            texts = [item.text for item in embedded_items]
            embeddings = [item.embedding for item in embedded_items]
            np_embeddings = np.array(embeddings, dtype=np.float32)

            # üìù Chu·∫©n b·ªã metadata cho t·ª´ng embedding
         
            metadatas = [
                {
                    "frame_id": str(item.frame_id) if item.frame_id is not None else None,
                    "video_id": str(item.video_id) if item.video_id is not None else None,
                    "scene_id": str(item.scene_id) if item.scene_id is not None else None,
                    "text": str(item.text) if item.text is not None else None
                }
                for item in embedded_items
            ]  # type: ignore  # ‚ö° Bypass type checker for Chroma metadatas

            # L∆∞u v√†o Chroma, bao g·ªìm c·∫£ metadata
            safe_metadatas = [
                {k: (v if v is not None else "") for k, v in meta.items()}
                for meta in metadatas
            ]
            collection.add(
                ids=ids,
                embeddings=np_embeddings,
                documents=texts,
                metadatas=safe_metadatas  # type: ignore
            )
            self.logger.info("L∆∞u embedding th√†nh c√¥ng v√†o Chroma.")
            return True
        except Exception as e:
            self.logger.error(f"L·ªói khi l∆∞u embedding v√†o Chroma: {e}")
            return False
 
    @tool(
        name="extract_statements_from_frame",
        description="Nh·∫≠n v√†o m·ªôt frame h√¨nh ·∫£nh, tr√≠ch xu·∫•t danh s√°ch object, enrich object (gom nh√≥m), sinh nhi·ªÅu statement cho m·ªói object (m·ªói kh√≠a c·∫°nh), v√† sinh statement v·ªÅ quan h·ªá gi·ªØa c√°c object (bao g·ªìm c·∫£ nh√≥m) b·∫±ng Video-LLaVA.",
        cache_results=False
    )
    async def extract_statements_from_frame(self, frame_info: FrameInfo) -> List[StatementItem]:
        """
        üì∏ Nh·∫≠n v√†o m·ªôt FrameInfo (ch·ª©a ·∫£nh, frame_id, video_id, scene_id), tr√≠ch xu·∫•t danh s√°ch object, enrich object (gom nh√≥m), sinh nhi·ªÅu statement cho m·ªói object (m·ªói kh√≠a c·∫°nh), v√† sinh statement v·ªÅ quan h·ªá gi·ªØa c√°c object (bao g·ªìm c·∫£ nh√≥m) b·∫±ng Video-LLaVA.
        Args:
            frame_info: FrameInfo - Th√¥ng tin v·ªÅ frame h√¨nh ·∫£nh
        Returns:
            List[StatementItem] - Danh s√°ch statement ƒë√£ tr√≠ch xu·∫•t (bao g·ªìm metadata)
        """
        frame = frame_info.frame
        frame_id = frame_info.frame_id
        video_id = frame_info.video_id
        scene_id = frame_info.scene_id

        # B∆∞·ªõc 1: Tr√≠ch xu·∫•t danh s√°ch object b·∫±ng h√†m n·ªôi b·ªô _run_llava_inference
        prompt_objects = "Li·ªát k√™ t·∫•t c·∫£ c√°c ƒë·ªëi t∆∞·ª£ng xu·∫•t hi·ªán trong ·∫£nh, tr·∫£ v·ªÅ d∆∞·ªõi d·∫°ng danh s√°ch, kh√¥ng gi·∫£i th√≠ch."
        objects_text = self._run_llava_inference(frame, prompt_objects)

        objects = []
        if '[' in objects_text and ']' in objects_text:
            try:
                objects = eval(objects_text)
                if not isinstance(objects, list):
                    objects = re.split(r',\s*', objects_text.strip("[] "))
            except Exception:
                objects = re.split(r',\s*', objects_text.strip("[] "))
        else:
            objects = re.split(r',\s*', objects_text)
        objects = [o.strip('"\' \\') for o in objects if o.strip()]
        self.logger.info(f"ƒê·ªëi t∆∞·ª£ng ph√°t hi·ªán: {objects}")

        # B∆∞·ªõc 2: Sinh nhi·ªÅu statement cho t·ª´ng object (m·ªói statement m√¥ t·∫£ m·ªôt kh√≠a c·∫°nh kh√°c nhau)
        statements = []
        for obj in objects:
            # üìù Prompt: y√™u c·∫ßu tr·∫£ v·ªÅ nhi·ªÅu c√¢u, m·ªói c√¢u m√¥ t·∫£ m·ªôt kh√≠a c·∫°nh kh√°c nhau c·ªßa object
            prompt_obj_stmt = (
                f"Li·ªát k√™ nhi·ªÅu c√¢u m√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ ƒë·ªëi t∆∞·ª£ng '{obj}' trong ·∫£nh n√†y, "
                f"m·ªói c√¢u t·∫≠p trung v√†o m·ªôt kh√≠a c·∫°nh kh√°c nhau nh∆∞: ƒë·∫∑c ƒëi·ªÉm nh·∫≠n d·∫°ng, tr·∫°ng th√°i, h√†nh ƒë·ªông, v·ªã tr√≠ trong khung h√¨nh, m√†u s·∫Øc, k√≠ch th∆∞·ªõc, thu·ªôc t√≠nh n·ªïi b·∫≠t... "
                f"Ch·ªâ tr·∫£ v·ªÅ danh s√°ch c√°c c√¢u, kh√¥ng gi·∫£i th√≠ch th√™m."
            )
            obj_desc_text = self._run_llava_inference(frame, prompt_obj_stmt).strip()  # üöÄ G·ªçi h√†m n·ªôi b·ªô thay v√¨ await processor
            # T√°ch c√°c c√¢u m√¥ t·∫£ (m·ªói c√¢u l√† m·ªôt statement ri√™ng)
            obj_descs = re.split(r'(?<=[.!?])\s+', obj_desc_text)
            obj_descs = [desc for desc in obj_descs if len(desc.strip()) > 5]
            for desc in obj_descs:
                statements.append(StatementItem(
                    text=desc,
                    frame_id=frame_id,
                    video_id=video_id,
                    scene_id=scene_id
                ))

        # B∆∞·ªõc 2.5: L√†m gi√†u object b·∫±ng c√°ch ph√°t hi·ªán v√† th√™m c√°c nh√≥m ƒë·ªëi t∆∞·ª£ng m·ªõi (enriched objects)
        # üß† Prompt: ph√°t hi·ªán c√°c nh√≥m ƒë·ªëi t∆∞·ª£ng c√≥ li√™n h·ªá, t∆∞∆°ng ƒë·ªìng, ho·∫∑c t·∫°o th√†nh m·ªôt th·ª±c th·ªÉ l·ªõn h∆°n; th√™m t√™n nh√≥m v√†o objects ƒë·ªÉ c√°c b∆∞·ªõc sau c≈©ng x·ª≠ l√Ω nh√≥m n√†y
        if len(objects) >= 2:
            prompt_group = (
                f"C√≥ c√°c ƒë·ªëi t∆∞·ª£ng sau trong ·∫£nh: {', '.join(objects)}. "
                f"H√£y li·ªát k√™ c√°c nh√≥m ƒë·ªëi t∆∞·ª£ng c√≥ th·ªÉ ƒë∆∞·ª£c xem l√† m·ªôt th·ª±c th·ªÉ ho·∫∑c nh√≥m m·ªõi d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng, li√™n h·ªá, ho·∫∑c t·∫°o th√†nh m·ªôt kh·ªëi/th·ª±c th·ªÉ l·ªõn h∆°n. "
                f"M·ªói nh√≥m tr·∫£ v·ªÅ m·ªôt d√≤ng m√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ nh√≥m ƒë√≥ v√† c√°c th√†nh ph·∫ßn c·ªßa n√≥. N·∫øu kh√¥ng c√≥ nh√≥m n√†o th√¨ tr·∫£ v·ªÅ r·ªóng."
            )
            group_text = self._run_llava_inference(frame, prompt_group).strip()
            group_descs = re.split(r'(?<=[.!?])\s+', group_text)
            group_descs = [desc for desc in group_descs if len(desc.strip()) > 5]
            # Th√™m t√™n nh√≥m v√†o objects ƒë·ªÉ x·ª≠ l√Ω ti·∫øp c√°c b∆∞·ªõc sau (v√≠ d·ª•: quan h·ªá gi·ªØa nh√≥m v√† object kh√°c)
            enriched_objects = []
            for desc in group_descs:
                # üìù T√¨m t√™n nh√≥m (gi·∫£ ƒë·ªãnh t√™n nh√≥m l√† c·ª•m ƒë·∫ßu ti√™n tr∆∞·ªõc d·∫•u hai ch·∫•m ho·∫∑c d·∫•u ph·∫©y)
                group_name = desc.split(':')[0].split(',')[0].strip() if ':' in desc or ',' in desc else desc[:30].strip()
                if group_name and group_name not in objects:
                    enriched_objects.append(group_name)
                statements.append(StatementItem(
                    text=desc,
                    frame_id=frame_id,
                    video_id=video_id,
                    scene_id=scene_id
                ))
            objects.extend(enriched_objects)  # ‚ö° Th√™m nh√≥m v√†o objects ƒë·ªÉ c√°c b∆∞·ªõc sau c≈©ng x·ª≠ l√Ω c√°c nh√≥m n√†y

        # B∆∞·ªõc 3: Sinh statement v·ªÅ quan h·ªá gi·ªØa c√°c object (bao g·ªìm c·∫£ object g·ªëc v√† enriched object n·∫øu c√≥ >=2 object)
        if len(objects) >= 2:
            # üìù Prompt chi ti·∫øt: m√¥ t·∫£ v·ªÅ lo·∫°i quan h·ªá (kh√¥ng gian, h√†nh ƒë·ªông, t∆∞∆°ng t√°c, vai tr√≤, c·∫£m x√∫c, v.v.) gi·ªØa t·∫•t c·∫£ c√°c object (bao g·ªìm c·∫£ nh√≥m)
            prompt_rel = (
                f"M√¥ t·∫£ chi ti·∫øt c√°c m·ªëi quan h·ªá ho·∫∑c t∆∞∆°ng t√°c gi·ªØa c√°c ƒë·ªëi t∆∞·ª£ng sau trong ·∫£nh: {', '.join(objects)}. "
                f"Bao g·ªìm c√°c kh√≠a c·∫°nh nh∆∞: v·ªã tr√≠ t∆∞∆°ng ƒë·ªëi, h√†nh ƒë·ªông t∆∞∆°ng t√°c, vai tr√≤, c·∫£m x√∫c, tr·∫°ng th√°i, ho·∫∑c b·∫•t k·ª≥ h√¨nh th·ª©c li√™n k·∫øt n√†o kh√°c. "
                f"Tr·∫£ v·ªÅ m·ªói quan h·ªá l√† m·ªôt c√¢u ri√™ng bi·ªát, kh√¥ng gi·∫£i th√≠ch th√™m."
            )
            rel_text = self._run_llava_inference(frame, prompt_rel).strip()
            rel_statements = re.split(r'(?<=[.!?])\s+', rel_text)
            rel_statements = [s for s in rel_statements if len(s.strip()) > 5]
            for rel_stmt in rel_statements:
                statements.append(StatementItem(
                    text=rel_stmt,
                    frame_id=frame_id,
                    video_id=video_id,
                    scene_id=scene_id
                ))

        return statements
